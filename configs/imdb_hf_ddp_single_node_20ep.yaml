experiment_name: "imdb_hf_ddp_single_node_20ep"
output_dir: "experiments/exp031_imdb_hf_ddp_single_node_20ep"

seed: 42

model:
  type: "hf_sequence_classifier"
  hf_model_name: "distilbert-base-uncased"
  num_classes: 2

data:
  dataset: "imdb_hf_tok"

training:
  epochs: 20
  batch_size: 16   # per GPU; HF models have heavier memory use

distributed:
  use_ddp: true
  backend: "nccl"
